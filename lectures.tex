\section{Лекции}

\subsection{Лекция 1}

\subsubsection*{Основные понятия теории случайных процессов}

Теория случайных процессов является развитием теории вероятностей, в ней изучаются не отдельные случайные величины или векторы, а их семейства
$\{X_t,t\in T\subseteq R\}$, зависящие от параметра времени $t$.
Случайным процессом называют семейство в измеримом пространстве $(S,B)$ и определённых на одном вероятностном пространстве $(\Omega, A, P)$.
Пространство $S$ называют пространством состояний случайного процесса.

В зависимости от вида множества параметров $T$ случайный процесс может быть с дискретным или непрерывным временем.
Если $T=\mathbb{Z}_+=\{0,1,2,...\}$ (множество неотрицательных целых числе), то случайный процесс $X_t,t\in T$ называют цепью.
В зависимости от вида $S$ случайный процесс может быть с дискретным или непрерывным пространством состояний.

Случайные процессы применяются для моделирования эволюции реальных стохастических систем. Примерами могут служить: броуновское движение частиц, процессы рождении и гибели в биологических системах, генетическая эволюция, системы массового обслуживания и так далее.

\subsubsection*{Общая классификация случайных процессов}

\begin{table}[ht]
	\centering
	\begin{tabularx}{\textwidth}{|c|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|}
		\hline
		\diagbox{$T$}{$S$}                                                            &
		Дискретное                                                                    &
		Непрерывное                                                                     \\
		\hline
		Дискретное                                                                    &
		Последовательность дискретных случайных величин                               &
		Последовательность непрерывных случайных величин                                \\
		\hline
		Непрерывное                                                                   &
		Случайный процесс с непрерывным временем и дискретным пространством состояний &
		Случайный процесс с непрерывным временем и непрерывным пространством состояний  \\
		\hline
	\end{tabularx}
\end{table}

\subsubsection*{Основные понятия теории случайных процессов}

Для любого набора $t_1, t_2, ..., t_n \in T$ вектор
$(X(t_1), X(t_2),..., X(t_n))$ называется конечномерным сечением или $n$-мерным сечением случайного процесса $\{X_t, t\in T\}$.
При фиксированном $\omega \in \Omega$ отображение $t \rightarrow X_t(\omega)$ называется траекторией или выборочной функцией случайного процесса
$\{X_t,\in T \}$.
Семейство $\sigma$-алгебр \{$F_t, t\in T\}$ называется фильтрацией, если
$F_s \subset F_t \subset A$ для всех $s<t$, $s,t\in T$.
Случайный процесс $\{X_t,t\in T\}$ согласован с фильтрацией $\{F_t,t\in T\}$, если случайная величина $X_t$ измерима относительно $F_t$ для всех $t\in T$.

Пусть $S\subseteq R$, $S\in B(R)$, $B=B(S)$.
Случайный процесс называется регулярным, если его траектории в каждой точке $t\in T$ непрерывны справа и имеют конечные пределы слева.
Случайные процессы $\{X_t,t\in T\}$ и $\{Y_t,t\in T\}$ называются стохастически эквивалентными в широком смысле, если для всех $B_i\in B$, $i=1,..,n$, $t_1<t_2<...<t_{n-1}<t_n\in T$, верно равенство $P(X(t_1)\in B_1,...,X(t_n)\in B_n)=P(Y(t_1)\in b_1,...,Y(t_n)\in B_n)$.
Случайные процессы $\{X_t,t\in T\}$ и $\{Y_t, t\in T\}$ называются стохастически эквивалентными, если $P(X(t)=Y(t))=1$ для всех $t\in T$.

Пусть $t_1,t_2,...,t_n\in T$, $t(n)=(t_1,t_2,...,t_n)$, $X(t)=(X(t_1),X(t_2),...,X(t_n))$ - $n$-мерное сечение, $F_{t(n)}(x_1,x_2,...,x_n)=P(X(t_1)\leq x_1, ...,X(t_n)\leq x_n)$ - его функция распределения.
Для любых $t_1,t_2,...,t_n\in T$ $F_{t(n)}(x_1,x_2,...,x_n)$ удовлетворяют всем свойствам функции распределений случайных векторов.
Кроме того, условиям согласованности:
1) $F_{t(n)}(x_1,x_2,...,x_n)=F_{\sigma (t(n))}(x_{\sigma(1)},x_{\sigma(2)},...,x_{\sigma (n)})$, $\sigma (t(n))=(t_{\sigma (1)}, t_{\sigma (2)}, ..., t_{\sigma (n)})$, $\sigma \in S_n$ - группа перестановок;
2) $F_{t(n)}(x_1,...,x_m,+\infty,...,+\infty)=F_{t(m)}(x_1,x_2,...,x_m)$.
Теорема Колмогорова. Пусть задано семейство функций распределения
$F_{t(n)}(x_1,x_2,..x_n)$, удовлетворяющих условиям 1 и 2.
Тогда существует вероятностное пространство $(\Omega, A, P)$ и случайный процесс $\{X_t,t\in T\}$ с данными функциями распределения.

Полная информация о случайном процессе $\{X_t, t\in T\}$ содержится в функциях распределения всех его конечномерных сечений.
В общем случае найти все эти функции распределения практически невозможно.
Эта задача иногда упрощается при рассмотрении марковских случайных процессов.
Случайный процесс $\{X_t, t\in T\}$ называется марковским, если выполняется равенство условных вероятностей
$P(X(t_n)\in B_n | X(t_1)\in B_1, ..., X(t_{n-1})\in B_{n-1})=P(X(t_n)\in B_n | X(t_{n-1})\in B_{n-1})$ для всех $t_1<t_2<...<t_{n-1}<t_n \in T$, $B_i \in B$, $i=1,...,n$.

Вероятности конечномерных сечений для произвольного процесса \\
$P(X(t_1)\in B_1, ..., X(t_{n-1}) \in B_{n-1}, X(t_n) \in B_n) =\\
	P(X(t_n)\in B_n |X(t_1)\in B_1,...,X(t_{n-1})\in B_{n-1})\cdot P(X(t_{n-1})\in B_{n-1} |X(t_1)\in B_1,...,X(t_{n-2})\in B_{n-2})\cdot ... \cdot P(X(t_2)\in B_2 | X(t_1)\in B_1) \cdot P(X(t_1)\in B_1)$.

Вероятности конечномерных сечений для марковского процесса при
$t_1<t_2<...<t_{n-1}<t_n$,
$P(X(t_1)\in B_1,...,X(t_{n-1})\in B_{n-1},X(t_n)\in B_n) = \\
	P(X(t_n)\in B_n | X(t_{n-1})\in B_{n-1}) \cdot P(X(t_{n-1})\in B_{n-1} | X(t_{n-2})\in B_{n-2}) \cdot ... \cdot P(X(t_2)\in B_2 | X(t_1) \in B_1) \cdot P(X(t_1) \in B_1 )$.

\subsection{Лекция 2}

\subsubsection*{Цепи Маркова}

Последовательность случайных величин $\{X_k\}_{k=0}^\infty$ со значениями в $S=\{E_1,E_2,...\}$ называется цепью Маркова, если выполняется равенство условных вероятностей $P(X_{i_k}=E_{j_k} | X_{i_1}=E_{J_1},...,X_{i_{k-1}}=E_{j_{k-1}}) = P(X_{i_{k}}=E_{j_{k}} | X_{i_{k-1}}=E_{j_{k-1}})$ для произвольных $i_1<i_2<...<i_{k-1}<i_k$ и любых $E_{j_{1}},...,E_{j_{k}}$.

Если вероятности $p_{ij}=P(X_{k+1}=E_j | X_l = E_i)$ не зависят от $k$, то цепь Маркова называется однородной. При этом $p_ij$ называются переходными вероятностями, а матрица $P=(p_ij)$ называется матрицей вероятностей перехода за один шаг или переходной матрицей.

В однородной цепи Маркова вероятности $p_{ij}(m)=P(X_{k+m}=E_j | X_k = E_i)$ тоже не зависят от $k$. Матрица $P(m)=(p_{ij}(m))$ называется матрицей вероятностей перехода за $m$ шагов. При этом $0<=P-{ij}(m)<=1$ и $\sum_j p_{ij}(m)=1$. Матрица с двумя такими свойствами называется стохастической.

Вектор $\vec p (m)=(p_1(m), p_2(m), ...)$, где $p_i(m)=P(X_m=E_i)$, называется вектором распределения вероятностей через $m$ шагов. При этом $0\leq p_i(m)\leq 1$ и $\sum_i p_i(m) = 1$.

Вектор $\vec p (0)=(p_1(0),p_2(0),...)$ называется начальным распределением вероятностей цепи Маркова.

\subsubsection*{Свойства цепей Маркова}

Пусть $\{X_k\}_{k=0}^\infty $ - однородная цепь Маркова. Тогда $P(k)=P^k$.

Пусть $\{X_k\}_{k=0}^\infty$ - однородная цепь Маркова. Тогда $\vec p(m)= \vec p (0) P(m)$.

В качестве следствия получаем, что $\vec p(m)=\vec (0)P^m$.
Зная $\vec p(0)$ и $P$ можно найти все конечномерные распределения цепи Маркова: для произвольных $i_1<i_2<...<i_k$ и любых $E_{j_1},...,E_{j_k}$ получаем $P(X_{i_1}=E_{j_1},...,X_{i_k}=E_{j_k}) = P(X_{i_1}=E_{j_1})P(X_{i_2}=E_{j_2}|X_{i_1}=E_{j_1})...P(X_{i_k}=E_{j_k}|X_{i_{k-1}}=E_{j_{k-1}}) = p_{j_1}(i_1)p_{j_1j_2}(i_2-i_1)...p_{j_{k-1}j_k}(i_k-i_{k-1})$.

\subsubsection*{Стационарные распределения}

Пусть $\{X_k\}_{k=0}^\infty$ - однородная цепь Маркова со значениями в $S=\{E_1,E_2,...\}$, с переходной матрицей $P=(p_{ij})$ и начальным распределением вероятностей $\vec p(0)=(p_1(0),p_2(0),...)$.
Если существует $\lim\limits_{m \to \infty} \vec{p}(m) = \lim\limits_{m \to \infty} \vec p (0) P^m = \vec p (\infty )$, то $\vec p (\infty)$ называется предельным распределением вероятностей с начальным распределением $\vec p (0)$.
Если для распределения вероятностей $\vec r (0) = (r_1(0),r_2(0),...)$ выполняется условие $\vec r (m)=\vec r(0)$ для всех $m \geq 1$, то $\vec r = (r_1,r_2,...)=\vec r(0)$ называется стационарным распределением вероятностей.

Если  предельное распределение вероятностей $\vec p (\infty)$ с начальным распределением $\vec p(0)$ существует, то оно будет стационарным, так как $\vec p(\infty)= \lim\limits_{m\to \infty } \vec p (m)= \lim\limits_{m \to \infty} \vec p (m+1) = [\lim\limits_{m \to \infty } \vec p (m)]P = \vec p (\infty ) P$.
Стационарное распределение вероятностей $\vec r = (r_1,r_2,...)$ удовлетворяет уравнениями $r_i=\sum_j r_j p_{ij}$, $i=1,2,...$ и $\sum_j r_j=1$ (уравнение нормировки).

Для конечной цепи Маркова с $n$ состояниями получается система
\[
	\begin{aligned}
		r_1 & = r_1 p_{11} + r_2 p_{21} + \dots + r_n p_{n1}, \\
		r_2 & = r_1 p_{12} + r_2 p_{22} + \dots + r_n p_{n2}, \\
		    & \ \ \vdots                                      \\
		r_n & = r_1 p_{1n} + r_2 p_{2n} + \dots + r_n p_{nn}, \\
		1   & = r_1 + r_2 + \dots + r_n.
	\end{aligned}
\]

Система из первых $n$ уравнений вырожденная, так как из $\vec{r} = \vec{r}P$
следует
$\vec{r}(P - E) = \vec{0}$, ($E$ - единичная матрица),
а матрица $(P - E)$ вырожденная:
\[
	\det(P - E) =
	\det \begin{pmatrix}
		p_{11} - 1 & \dots  & p_{1n}     \\
		\vdots     & \ddots & \vdots     \\
		p_{n1}     & \dots  & p_{nn} - 1
	\end{pmatrix}
	=
	\det \begin{pmatrix}
		p_{11} - 1 & \dots  & 0      \\
		\vdots     & \ddots & \vdots \\
		p_{n1}     & \dots  & 0
	\end{pmatrix}
	= 0.
\]

\subsubsection*{Эргодические цепи Маркова}

Цепь Маркова с переходной матрицей $P = (p_{ij})$ называется эргодической, если

1) существует предел
$\lim\limits_{k \to \infty} p_{ij}(k) = q_{ij};$

2) $q_{ij}$ не зависят от $i$:
$q_{ij} = q_j;$

3)
$q_j > 0 \quad \text{для всех } j.$

Теорема 1. Цепь Маркова эргодическая тогда и только тогда, когда

1) для любого начального распределения $\vec{p}(0)$ существует предел
$\lim\limits_{k \to \infty} p_{j}(k) = q_j;$

2) $q_j$ не зависят от начального распределения;

3) $q_j > 0$ для всех $j$.

Теорема 2. Если для конечной цепи Маркова с переходной матрицей $P=(p_{ij})$ среди корней характеристического уравнения $|P-\lambda E|=0$ условию $|\lambda|=1$ удовлетворяет только корень $\lambda=1$, то предельное распределение существует.

Теорема 3. Если условиях теоремы 2 корень $\lambda=1$ имеет кратность 1, то предельное распределение не зависит от начального распределения.

Теорема 4. (Теорема Маркова) Если для конечной цепи Маркова с переходной матрицей $P=(p_{ij})$ существует такое $S$, что $p_{ij}(s)>0 (P(s)=\{p_{ij}(s)\}=P^s)$ для всех $i$ и $j$, то цепь Маркова является эргодической.

Лемма. Пусть $Q=(q_{ij})$ - стохастическая матрица размерности $n \times n$,
$
	\vec{a} = \begin{pmatrix}
		a_1    \\
		a_2    \\
		\vdots \\
		a_n
	\end{pmatrix}
$ - произвольный вектор-столбец (размерности $n \times 1$), $\vec{b}=Q\vec{a}$; $m_{\vec{a}}=\min a_i$, $M_{\vec{a}}=\max a_i$ ($m_{\vec{b}}$ и $M_{\vec{b}}$ определяются для $\vec{b}$ аналогично).
Тогда:

1) $m\vec{a}\leq m\vec{b} \leq M\vec{b} \leq M\vec{a}$;

2) Если $q_{ij} \geq \varepsilon$ $\forall i,j$, то $M_{}\vec{b}-m_{\vec{b}} \leq  (1-2\varepsilon) (M_{}\vec{a}-m_{\vec{a})}$

\subsubsection*{Классификация состояний цепи Маркова}

Состояние $j$ достижимо из состояния $i$ [ обозначение: $i \to j$], если $\exists k: p_{ij}(k)>0$.
Очевидно, что из $i \to j$ и $j \to s$ следует $i \to s$.
Состояния $i$ и $j$ - сообщающиеся [обозначение $i \rightleftarrows j$] если $i \to j$ и $j \to i$.
Состояние $i$ - существенное, если из $i \to j$ следует $j \to i$.
Если $i$ - существенное состояние и $i \to j$, то состояние $j$ - существенное
Если для состояния $i$ существует такое состояние $j$, что $j$ достижимо из состояния $i$, но $i$ недостижимо из $j$, то состояние $i$ называется несущественным.

Пусть для существенного состояния $i$ $S(i)={j:i \rightleftarrows j}$. Все состояния $j\in S(i)$ являются существенными. Пространство $S$ всех состояний цепи Маркова можно представить в виде $S=S(i_1)\cup S(i_2)\cup ...\cup E$, где $E$ - множество всех несущественных состояний.

Цепь Маркова - неприводимая, если $S=S(i)$ для всех $i\in S$. Периодом состояния $i\in S$ называется $k_i=НОД(k: p_{ii}(k)>0)$.

Теорема. Если $i \rightleftarrows j$, то $k_i=k_j$.

\subsection{Лекция 3}

Обозначим через $f_{ij}(m)$ вероятность того, что из состояния $i$ первый раз попадаем в состояние $j$ на шаге $m$
$f_{ij}(m)=P(X_m=E_j,X_k\ne E_j (0<j<m) | X_0 =E_i))$, через $g_{ij}$ вероятность того, что из состояния $i$ попадаем в состояние $j$ бесконечное число раз. По формуле $f^*_{ij}=\sum_{m=1}^\infty f_{ij}(m)$ находится вероятность того, что исходя из состояния $i$ попадём в состояние $j$ хотя бы один раз.
Верны следующие утверждения:

1) $g_{ij}=\lim_{m \to \infty } \sum _s p_{is}(m) f^*_{sj}$;

2) $g_{ij}=f^*_{ij}g_{jj}$;

3) $i \to j \;\Leftrightarrow\; f_{ij}^* > 0$;

4) $i \rightleftarrows j \;\Leftrightarrow\; f_{ij}^* f_{ji}^* > 0$.

Состояние $i$ называется возвратным, если $f^*_{ii}=1$, и невозвратным, если $f^*_{ii}<1$.
Верны следующие утверждения:

1) $g_{ij}=f^*_{ij}$, если состояние $j$ возвратно, и $g_{ij}=0$, если $j$ невозвратно;

2) $g_{ii}=1$, если состояние $i$ возвратно, и $g_{ii}=0$, если $i$ невозвратно;

3) Если состояние $i$ несущественное, то $i$ невозвратное;

4) Если $g_{ii}=1$ и $f^*_{ij}>0$, то $g_{jj}=1$;

5) Если состояние $i$ возвратно и $i \to j$, то $j$ возвратно и $g_{ij}=g_{ji}=1$;

6) Состояние $i$ возвратное если ряд $\sum_{m=1}^\infty p_{ii}(m)$ расходится, и $i$ невозвратное, если ряд сходится.


Возвратное состояние $i$ называется положительным, если $\lim_{m \to \infty } p_{ii}(mk_i)>0$, и нулевым, если $\lim_{m \to \infty } p_{ii}(mk_i)=0$.
Обозначим через $\mu_{ii}$ среднее время возвращения в состояние $i$ $\mu_{ii}=\sum_{m=1}^\infty mf_{ii}(m)$.
Верны следующие утверждения:

1) Если состояние $i$ возвратное с периодом $k_i$, то $\lim_{m \to \infty} p_{ii} (mk_i)=\frac{k_i}{\mu _{ii}}$;

2) Возвратное состояние $i$ положительно $\Leftrightarrow$ $\mu _{ii}< \infty$;

3) Если состояние $i$ возвратное положительное и $i \rightleftarrows j$, то состояние $j$ так же положительное;

4) Если состояние $i$ возвратное положительное, то $\lim_{m \to \infty} \frac{1}{m} \sum_{k=1}^m p_{ii}(k)=1\frac{1}{\mu _{ii}}$.

Цепь Маркова - неприводимая, если $S=S(i)$ для всех $i\in S$.

Период состояния $i$: $k_i=НОД(k: p_{ii}(k)>0)$.

Цепь Маркова - апериодическая, если $k_i=1$ для всех $i\in S$.

Цепь Маркова - эргодическая $\Leftrightarrow$ она неприводимая и апериодическая.

\subsubsection*{Эргодические цепи Маркова}

Теорема 1. (эргодическая теорема для конечной цепь Маркова). Любая неприводимая непериодическая цепь Маркова $\{v_n, n\geq 0 \}$ с конечным множеством состояний $g$ является эргодической.

Теорема 2. (эргодическая теорема Фостера для счётной цепи Маркова) $\{v_n, n \geq 0 \}$ была эргодической, необходимо и достаточно существование нетривиального решения $\{p_i, i \geq 1 \}$ СУР (4.4)??? такого, что $\sum_{i=1}^\infty |p_i|<\infty$.
Решение $\{p_i, i \geq 1 \}$ с точностью до нормирующего множителя совпадает с предельным (стационарным) распределением.

Теорема 3. (для счётной цепи Маркова). Для того, чтобы  неприводимая непериодическая цепь Маркова $\{v_n, n\geq 0 \}$ была эргодической, достаточно существование числа $\varepsilon > 0$, целого числа $i_0$ и набора неотрицательных чисел $x_1,x_2,...$ таких что
$\sum_{j=1}^\infty p_{ij} x_j \leq x_i - \varepsilon$, $i \geq i_0$;
$\sum_{j=1}^\infty p_{ij} x_i < \infty$, $i < i_0$;

\subsubsection*{Марковские процессы с непрерывным временем}

Случайный процесс $X_t, t \geq 0$ называется марковским, если для любого целого неотрицательного $m$, любых моментов времени $0\leq s_1<s_2<...<s_m<s$, $t>0$, любого набора состояний $E_{i_1}, E_{i_2},...,E_{i_m},E_i, E_j$ выполнено равенство $P(X_{s+t}=E_j | X_{s_1}=E_{i_1}, ..., X_{s_m}=E_{i_m}, X_s=E_i)= P(X_{s+t}=E_j | X_s=E_i)$

\subsubsection*{Однородный марковский процесс с непрерывным временем}

Процесс $X_t$ называется однородным (по времени), если условная вероятность $P(X_{s+t}=E_j|X_s=E_i)$ перехода из состояния $E_i$ в состояние $E_j$ за время $t$ не зависит от $s$.
Обозначим $p_{ij}(t)=P(X_{s+t}=E_j | X_s=E_i)$.
Свойства:

1) $p_{ij}(0)=0$, если $i\ne j$, а $p_{ii}(0)=1$;

2) $0\leq p_{ij}(t)\leq 1$;

3) $\sum _j p_{ij}(t)=1$.

Матрица вероятностей переходя за время $t$: $P(t)=||p_{ij}(t)||$.
Предполагаем что переходные вероятности $p_{ij}(t)$ дифференцируемы в нуле: $p'_{ij}(0)=\lambda_{ij}$, при $i\ne j$ $p_{ij}(t)=\lambda_{ij}t+o(t)$, $p_{ii}(t)=1+\lambda_{ii}t+o(t)$.
$P'(0)=\Lambda=||\lambda_{ij}||$ - матрица интенсивностей (плотностей вероятностей) перехода.
При $i\ne j$ $\lambda_{ij}$ называется интенсивностью (плотностью вероятности) перехода из $E_i$ в $E_j$.

\subsection{Лекция 4}

\subsubsection*{Марковский процесс с непрерывным временем}

Величина $\lambda_{ji} \cdot p_j(t)$ называется потоком вероятности из состояния $E_j$ в состояние $E_i$ в момент времени $t$.

Из дифференциальных уравнений Колмогорова следует: произвольная вероятности состояния равна
сумме всех потоков вероятностей, приходящих в это состояние, минус сумма всех потоков вероятностей,
выходящих из этого состояния.

\textbf{Свойства матрицы интенсивностей перехода:}

1) $\lambda_{ij}\geq 0$, при $i\ne j$;

2) $\lambda_{ii}<0$;

3) $\sum_j \lambda_{ij}=0$, $\lambda_{ii}=-\sum_{j\ne i} \lambda_{ij}$.

\textbf{Система дифференциальных уравнений Колмогорова:}

$\frac{dp_i(t)}{dt}=\sum_j \lambda_{ji} p_j(t)=\lambda_{ii} p_i(t) + \sum_{j\ne i} \lambda_{ji} p_j(t)
	=\sum_{j\ne i} \lambda_{ji} p_j(t) - p_i(t) \sum_{j\ne i} \lambda_{ji}$

---

$\left\{ {P}(t) \right\}_{t \ge 0}$

1) ${P}(0) = {I}$,

2) ${P}(t+s) = {P}(t)\,{P}(s)$,

3) $\vec{p}(t) = \vec{p}(0)\,{P}(t)$.

---

\[
	\lambda_{ij} = \lim_{\tau \to +0}
	\frac{p_{ij}(\tau) - p_{ij}(0)}{\tau}
\]

\[
	i \ne j \Rightarrow
	\lambda_{ij} = \lim_{\tau \to +0}
	\frac{p_{ij}(\tau)}{\tau} \ge 0,
	\qquad
	i = j \Rightarrow
	\lambda_{ii} = \lim_{\tau \to +0}
	\frac{p_{ii}(\tau) - 1}{\tau} \le 0.
\]

---


\[
	\sum_j p_{ij}(t) = 1,
	\qquad
	\left( \sum_j p_{ij}(t) \right)'_{t=0} = (1)' = 0,
\]

\[
	\sum_j \lambda_{ij} = 0,
	\qquad
	\Rightarrow
	\qquad
	\lambda_{ii} = - \sum_{j \ne i} \lambda_{ij}.
\]


---

\[
	\vec{p}'(t)
	= \lim_{\tau \to 0}
	\frac{\vec{p}(t+\tau) - \vec{p}(t)}{\tau}
	=
	\lim_{\tau \to 0}
	\frac{\vec{p}(t){P}(\tau) - \vec{p}(t)}{\tau}
\]

\[
	= \vec{p}(t)
	\lim_{\tau \to 0}
	\frac{P(\tau) - P(0)}{\tau}
	= \vec{p}(t)\,{\Lambda}.
\]

---

\begin{align*}
	p_i'(t)
	 & = \sum_j p_j(t)\,\lambda_{ji}
	\\[4pt]
	 & = \sum_{j \ne i} p_j(t)\,\lambda_{ji} + p_i(t)\,\lambda_{ii}
	\\[4pt]
	 & = \sum_{j \ne i} p_j(t)\,\lambda_{ji} - \sum_{j \ne i} p_i(t)\,\lambda_{ij}.
\end{align*}

---

\begin{align*}
	{P}'(t)
	 & = \lim_{\tau \to 0}
	\frac{{P}(t+\tau) - {P}(t)}{\tau}
	\\[4pt]
	 & = \lim_{\tau \to 0}
	\frac{{P}(t){P}(\tau) - {P}(t)}{\tau}
	\\[4pt]
	 & = {P}(t)
	\lim_{\tau \to 0}
	\frac{{P}(\tau) - {P}(0)}{\tau}
		= {P}(t)\,{\Lambda}
	\\[4pt]
	 & = \lim_{\tau \to 0}
	\frac{{P}(t){P}(\tau) - {P}(t)}{\tau}
	= \lim_{\tau \to 0}
	\frac{{P}(t+\tau) - {P}(t)}{\tau}
	\\[4pt]
	 & =
	\left(
	\lim_{\tau \to 0}
	\frac{{P}(t+\tau) - {P}(t)}{\tau}
	\right)
	{P}(t)
	= {\Lambda}\,{P}(t).
\end{align*}

---


Дифференциальные уравнения Колмогорова

Векторная форма дифференциальных уравнений Колмогорова для вероятностей состояний:
$\vec{p'}(t)=\vec{p}(t)\Lambda$, где $\vec{p}(t)=(p_0(t),p_1(t),...,p_n(t),...)$.

Прямое уравнение Колмогорова: $P'(t)=P\Lambda$.

Обратное уравнение Колмогорова: $P'(t)=\Lambda P(t)$.

---

Марковский процесс с непрерывным временем ($\vec{p}(t), \{P(t)\}_{t>0}$) - эргодический:
\[
	\exists \lim_{t \to +\infty} {P}(t) = {Q}
	=
	\begin{pmatrix}
		q_{11} & q_{12} & \cdots \\
		q_{21} & q_{22} & \cdots \\
		\vdots & \vdots & \ddots
	\end{pmatrix},
	\qquad
	q_{ij} > 0 \ \forall i,j.
\]

---

\begin{enumerate}
	\item
	      $\displaystyle
		      \exists \lim_{t \to +\infty}
		      \overline{\mathbf{p}}(t)
		      =
		      \overline{\mathbf{q}}
		      = (q_1, q_2, \ldots)
	      $

	\item предел не зависит от $\overline{\mathbf{p}}(0)$

	\item $q_j > 0 \ \forall j$
\end{enumerate}

---

Процесс Маркова$\{ X_t \}_{t \ge 0}$ — эргодический $\Longleftrightarrow$
1) неприводим, 2) существует стационарное распределение.
---

Распределение вероятностей состояний, которое не зависит от времени $p_i(t+\tau ) = p_i(t)=p_i$
для любых $t,\tau\leq 0$ и любых $i=1,2,...$ называется стационарным распределением.

Система линейных алгебраических уравнений для стационарных вероятностей
\[
	\begin{cases}
		\sum_j  \lambda_{ji} r_j = 0, \quad i=1,2,... \\
		\sum_j r_j = 1
	\end{cases}
\]

---

\textbf{Свойства матрицы интенсивностей перехода:}
\begin{enumerate}
	\item $\lambda_{ij} \ge 0 \quad$ при $i \ne j$;
	\item $\lambda_{ii} \le 0$;
	\item $\displaystyle \sum_j \lambda_{ij} = 0,
		      \qquad
		      \lambda_{ii} = - \sum_{j \ne i} \lambda_{ij}.$
\end{enumerate}

\vspace{1em}

\textbf{Система дифференциальных уравнений Колмогорова}
\[
	\frac{dp_i(t)}{dt}
	= \sum_j \lambda_{ji}\,p_j(t)
	= \lambda_{ii}\,p_i(t)
	+ \sum_{j \ne i} \lambda_{ji}\,p_j(t)
\]
\[
	= \sum_{j \ne i} \lambda_{ji}\,p_j(t)
	- p_i(t)\sum_{j \ne i} \lambda_{ij},
	\qquad i = 1, 2, \ldots
\]

\textbf{Стациорнаное распределение}

Из уравнений следует: при стационарном распределении для каждого стояния сумма всех потоков вероятностей, приходящих в это состояние, равна сумме всех потоков вероятностей, выходящих из этого состояния.

\[
	\sum_{j \ne i} \lambda_{ji} r_j = r_i \sum_{j \ne i} \lambda_{ij} r_i
\]

---

\subsubsection*{Время пребывания марковского процесса с непрерывным временем в состоянии}

Пусть $\tau(i)$ — время пребывания марковского процесса $X(t)$ в состоянии $i$.
Получаем
$P\bigl(\tau(i) > t\bigr)= \lim_{n \to \infty} [p_{ii}(\frac{t}{n})]^n.$

Но $p_{ii}\!\left(\tfrac{t}{n}\right)= 1 + \lambda_{ii}\tfrac{t}{n} + o\!\left(\tfrac{1}{n}\right).$
Пусть $\lambda_i = -\lambda_{ii} = \sum_{j \ne i} \lambda_{ij}$.

Тогда
$\lim_{n \to \infty} [p_{ii}(\frac{t}{n})]^n
	= \lim_{n \to \infty}
	\left[1 - \lambda_i \tfrac{t}{n} + o\!\left(\tfrac{1}{n}\right)\right]^n
	= e^{-\lambda_i t}.$

Значит, $F_{\tau(i)}(t) = 1 - e^{-\lambda_i t}$,
т.\,е. $\tau(i)$ имеет показатель­ное распределение с параметром $\lambda_i$.


\subsection{Лекция 5}

Пример. В системе 2 устройства и один мастер, проводящий ремонт.
Работа системы описывается марковским процессом $\{X_t, t\in [0, +\infty) \}$,
значением $X_t$ является число исправных устройств в момент времени $t$.
Каждое устройство выходит из строя с интенсивностью $\lambda=1$,
востановление устройства проходит с интенсивностью $\mu=2$.

Граф системы имеет вид:

\begin{center}
	\begin{tikzpicture}[
			>=Stealth, thick,
			state/.style = {draw, circle, minimum size=9mm, font=\small},
			e/.style   = {->, shorten >=2pt, shorten <=2pt},
			lbl/.style  = {font=\scriptsize, fill=white, inner sep=1pt}
		]

		% --- вершины ---
		\node[state] (Q1) at (0,0) {$2$};
		\node[state] (Q2) at (2.5,0) {$1$};
		\node[state] (Q3) at (5,0) {$0$};

		% --- рёбра ---
		% Q1
		\path[e, bend left=12]   (Q1) edge node[lbl] {$2$} (Q2);

		% Q2
		\path[e, bend left=12] (Q2) edge node[lbl] {$2$} (Q1);
		\path[e, bend left=12] (Q2) edge node[lbl] {$1$} (Q3);

		% Q3
		\path[e, bend left=12]   (Q3) edge node[lbl] {$2$} (Q2);

	\end{tikzpicture}
\end{center}

Найдём стационарные вероятности состояний.

---


Составим систему уравнений Колмогорова:
\[
	\begin{cases}
		p_0'(t) = -2p_0(t) + p_1(t);           \\
		p_1'(t) = 2p_0(t) - 3p_1(t) + 2p_2(t); \\
		p_2'(t) = 2p_1(t) - 2p_2(t).
	\end{cases}
\]

Решая систему уравнений для стационарных вероятностей:
\[
	\begin{cases}
		r_1 = 2r_0;         \\
		3r_1 = 2r_0 + 2r_2; \\
		r_1 = r_2;          \\
		r_0 + r_1 + r_2 = 1;
	\end{cases}
\]

находим
\[
	(r_0, r_1, r_2) = (0.2, 0.4, 0.4).
\]

---

\textbf{Задача 4.6.} \\
\textit{Два устройства и один мастер. Пусть $E_i$~--- работают $i$ устройств.}

\vspace{1em}

\begin{center}
	\begin{tikzpicture}[
			>=Stealth, thick,
			state/.style={draw, circle, minimum size=8mm, font=\small}
		]
		\node[state] (2) at (0,0) {2};
		\node[state] (1) at (2.5,0) {1};
		\node[state] (0) at (5,0) {0};

		\path[->] (2) edge[bend left=20] node[above] {$2\lambda$} (1);
		\path[->] (1) edge[bend left=20] node[below] {$\mu$} (2);

		\path[->] (1) edge[bend left=20] node[above] {$\lambda$} (0);
		\path[->] (0) edge[bend left=20] node[below] {$\mu$} (1);
	\end{tikzpicture}
\end{center}

\vspace{1em}

\[
	\begin{cases}
		2\lambda r_2 = \mu r_1,                     \\[4pt]
		(\lambda+\mu) r_1 = 2\lambda r_2 + \mu r_0, \\[4pt]
		\mu r_0 = \lambda r_1,                      \\[4pt]
		r_0 + r_1 + r_2 = 1.
	\end{cases}
\]

Из первого и третьего уравнений:
\[
	r_1 = \dfrac{2\lambda}{\mu} r_2,
	\qquad
	r_0 = \dfrac{\lambda}{\mu} r_1 = \dfrac{2\lambda^2}{\mu^2} r_2.
\]

Подставляем в нормировочное:
\[
	r_2\!\left(1 + \dfrac{2\lambda}{\mu} + \dfrac{2\lambda^2}{\mu^2}\right) = 1,
	\quad\Rightarrow\quad
	r_2 = \dfrac{\mu^2}{\mu^2 + 2\lambda\mu + 2\lambda^2}.
\]

Средняя доля времени простоя мастера: $r_2$

Средняя доля времени занятости мастера:
\[
	1 - r_2 = \dfrac{2\lambda(1+\mu)}{\mu^2 + 2\lambda\mu + 2\lambda^2}.
\]

\[
	r_1 = \dfrac{2\lambda\mu}{\mu^2 + 2\lambda\mu + 2\lambda^2},
	\qquad
	r_0 = \dfrac{2\lambda^2}{\mu^2 + 2\lambda\mu + 2\lambda^2}.
\]


\textbf{Задача 4.6} \quad [$\lambda = 1$, $\mu = 2$]

\vspace{1em}

\begin{center}
	\begin{tikzpicture}[
			>=Stealth, thick,
			state/.style={draw, circle, minimum size=8mm, font=\small}
		]
		\node[state] (2) at (0,0) {2};
		\node[state] (1) at (2.5,0) {1};
		\node[state] (0) at (5,0) {0};

		\path[->] (2) edge[bend left=20] node[above] {$2\lambda$} (1);
		\path[->] (1) edge[bend left=20] node[below] {$\mu$} (2);

		\path[->] (1) edge[bend left=20] node[above] {$\lambda$} (0);
		\path[->] (0) edge[bend left=20] node[below] {$\mu$} (1);
	\end{tikzpicture}
\end{center}

\vspace{1em}

\[
	\begin{cases}
		p_0'(t) = -2p_0(t) + p_1(t),           \\[4pt]
		p_1'(t) = 2p_0(t) + 2p_2(t) - 3p_1(t), \\[4pt]
		p_2'(t) = 2p_1(t) - 2p_2(t),           \\[4pt]
		p_2(0) = 1,\quad p_0(0) = p_1(0) = 0,  \\[4pt]
		p_0 + p_1 + p_2 = 1.
	\end{cases}
\]

$$p_i(t)=\pi_i (s)$$

\vspace{1em}
Переходим к изображению Лапласа:
$$
	\begin{cases}
		S \pi_0  = -2 \pi_0 + \pi_1,     \\
		S \pi_2 - 1 = 2 \pi_1 - 2 \pi_2. \\
	\end{cases}
$$

Сумма вероятностей:
\[
	\pi_0 + \pi_1 + \pi_2 = \frac{1}{S}.
\]

Из первого и последнего уравнений:
\[
	\pi_0 = \frac{\pi_1}{S + 2}, \qquad
	\pi_2 = \frac{1 + 2\pi_1}{S + 2}.
\]

Подставим:
\[
	\pi_1\!\left(\frac{1}{S + 2} + 1 + \frac{2}{S + 2}\right)
	= \text{[тут у Лобузова какой-то бред с числами]}.
\]

Следовательно:
\[
	p_1(t) = \frac{2}{5}\left(1 - e^{-5t}\right).
\]

Аналогично:
\[
	\pi_0 = \frac{1}{S} \cdot \frac{1}{5} - \frac{1}{3} \cdot \frac{1}{S + 2} + \frac{2}{15} \cdot \frac{1}{S + 5},
\]
\[
	p_0(t) = \frac{1}{5} - \frac{1}{3}e^{-2t} + \frac{2}{15}e^{-5t}.
\]

---

\[
	p_1(t) = \frac{2}{5} - \frac{2}{5} e^{-5t}
	\quad \xrightarrow[t \to +\infty]{} \quad
	\frac{2}{5},
\]

\[
	p_0(t) = \frac{1}{5} - \frac{1}{3} e^{-2t} + \frac{2}{15} e^{-5t}
	\quad \xrightarrow[t \to +\infty]{} \quad
	\frac{1}{5},
\]

\[
	p_2(t) = \frac{2}{5} + \frac{1}{3} e^{-2t} + \frac{4}{15} e^{-5t}
	\quad \xrightarrow[t \to +\infty]{} \quad
	\frac{2}{5}.
\]

\vspace{1em}

\[
	\pi_i(s) \; = \; p_i(t),
	\qquad
	p_i'(t) \; = \; s\,\pi_i(s) - p_i(0).
\]

---

Пусть $\tau$ — время нахождения в состоянии $i$,
а $\tau_{(s)}$ — время нахождения в этом состоянии после времени $s$.

\[
	P(\tau_{(s)} > t)
	= P(\tau > s + t \mid \tau > s)
	= \frac{e^{-\lambda (t + s)}}{e^{-\lambda s}}
	= e^{-\lambda t},
	\qquad [\,\lambda = \lambda_i\,].
\]

Отсюда
\[
	P(\tau_{(s)} \le t) =
	\begin{cases}
		0,                  & t < 0,   \\[6pt]
		1 - e^{-\lambda t}, & t \ge 0,
	\end{cases}
	\qquad
	\text{— показатель­ное распределение с параметром } \lambda.
\]

Следовательно $\tau_{(s)} \sim \tau$.

\subsubsection*{Процессы рождения и гибели. Процесс Пуассона}

Граф процесса рождения и гибели с конечным числом состояний

\begin{center}
	\begin{tikzpicture}[
			>=Stealth, thick,
			state/.style={draw, rectangle, minimum width=10mm, minimum height=8mm, font=\small, align=center}
		]

		% узлы
		\node[state] (0) at (0,0) {0};
		\node[state] (1) at (2,0) {1};
		\node[state] (2) at (4,0) {2};
		\node[state] (k) at (6,0) {$\dots$};
		\node[state] (n) at (8,0) {$n$};

		% стрелки вправо (рождения)
		\path[->] (0) edge[bend left=20] node[above] {$\lambda_0$} (1);
		\path[->] (1) edge[bend left=20] node[above] {$\lambda_1$} (2);
		\path[->] (2) edge[bend left=20] node[above] {$\lambda_2$} (k);
		\path[->] (k) edge[bend left=20] node[above] {$\lambda_{n-1}$} (n);

		% стрелки влево (гибели)
		\path[->] (1) edge[bend left=20] node[below] {$\mu_1$} (0);
		\path[->] (2) edge[bend left=20] node[below] {$\mu_2$} (1);
		\path[->] (k) edge[bend left=20] node[below] {$\mu_3$} (2);
		\path[->] (n) edge[bend left=20] node[below] {$\mu_n$} (k);

	\end{tikzpicture}
\end{center}

Система дифференциальных уравнений Колмогорова:

\[
	\begin{cases}
		p_0'(t) = -\lambda_0 p_0(t) + \mu_1 p_1(t), \\[4pt]
		p_k'(t) = \lambda_{k-1} p_{k-1}(t)
		- (\lambda_k + \mu_k) p_k(t)
		+ \mu_{k+1} p_{k+1}(t),
		 & 1 \le k < n,                             \\[4pt]
		p_n'(t) = \lambda_{n-1} p_{n-1}(t) - \mu_n p_n(t).
	\end{cases}
\]

---

Стационарные вероятности состояний $r_0, r_1, r_2, \ldots, r_n$ процесса рождения и гибели
с конечным числом состояний удовлетворяют системе линейных алгебраических уравнений:

\[
	\begin{cases}
		0 = -\lambda_0 r_0 + \mu_1 r_1, \\[4pt]
		0 = \lambda_{k-1} r_{k-1} - (\lambda_k + \mu_k) r_k + \mu_{k+1} r_{k+1},
		 & 1 \le k < n,                 \\[4pt]
		0 = \lambda_{n-1} r_{n-1} - \mu_n r_n.
	\end{cases}
\]

А также уравнению нормировки:
\[
	\sum_{k=0}^{n} r_k = 1.
\]