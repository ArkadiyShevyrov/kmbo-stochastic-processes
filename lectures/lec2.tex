
\subsection{Лекция 2}

\subsubsection*{Цепи Маркова}

Последовательность случайных величин $\{X_k\}_{k=0}^\infty$ со значениями в $S=\{E_1,E_2,...\}$ называется цепью Маркова, если выполняется равенство условных вероятностей $P(X_{i_k}=E_{j_k} | X_{i_1}=E_{J_1},...,X_{i_{k-1}}=E_{j_{k-1}}) = P(X_{i_{k}}=E_{j_{k}} | X_{i_{k-1}}=E_{j_{k-1}})$ для произвольных $i_1<i_2<...<i_{k-1}<i_k$ и любых $E_{j_{1}},...,E_{j_{k}}$.

Если вероятности $p_{ij}=P(X_{k+1}=E_j | X_l = E_i)$ не зависят от $k$, то цепь Маркова называется однородной. При этом $p_ij$ называются переходными вероятностями, а матрица $P=(p_ij)$ называется матрицей вероятностей перехода за один шаг или переходной матрицей.

В однородной цепи Маркова вероятности $p_{ij}(m)=P(X_{k+m}=E_j | X_k = E_i)$ тоже не зависят от $k$. Матрица $P(m)=(p_{ij}(m))$ называется матрицей вероятностей перехода за $m$ шагов. При этом $0<=P-{ij}(m)<=1$ и $\sum_j p_{ij}(m)=1$. Матрица с двумя такими свойствами называется стохастической.

Вектор $\vec p (m)=(p_1(m), p_2(m), ...)$, где $p_i(m)=P(X_m=E_i)$, называется вектором распределения вероятностей через $m$ шагов. При этом $0\leq p_i(m)\leq 1$ и $\sum_i p_i(m) = 1$.

Вектор $\vec p (0)=(p_1(0),p_2(0),...)$ называется начальным распределением вероятностей цепи Маркова.

\subsubsection*{Свойства цепей Маркова}

Пусть $\{X_k\}_{k=0}^\infty $ - однородная цепь Маркова. Тогда $P(k)=P^k$.

Пусть $\{X_k\}_{k=0}^\infty$ - однородная цепь Маркова. Тогда $\vec p(m)= \vec p (0) P(m)$.

В качестве следствия получаем, что $\vec p(m)=\vec (0)P^m$.
Зная $\vec p(0)$ и $P$ можно найти все конечномерные распределения цепи Маркова: для произвольных $i_1<i_2<...<i_k$ и любых $E_{j_1},...,E_{j_k}$ получаем $P(X_{i_1}=E_{j_1},...,X_{i_k}=E_{j_k}) = P(X_{i_1}=E_{j_1})P(X_{i_2}=E_{j_2}|X_{i_1}=E_{j_1})...P(X_{i_k}=E_{j_k}|X_{i_{k-1}}=E_{j_{k-1}}) = p_{j_1}(i_1)p_{j_1j_2}(i_2-i_1)...p_{j_{k-1}j_k}(i_k-i_{k-1})$.

\subsubsection*{Стационарные распределения}

Пусть $\{X_k\}_{k=0}^\infty$ - однородная цепь Маркова со значениями в $S=\{E_1,E_2,...\}$, с переходной матрицей $P=(p_{ij})$ и начальным распределением вероятностей $\vec p(0)=(p_1(0),p_2(0),...)$.
Если существует $\lim\limits_{m \to \infty} \vec{p}(m) = \lim\limits_{m \to \infty} \vec p (0) P^m = \vec p (\infty )$, то $\vec p (\infty)$ называется предельным распределением вероятностей с начальным распределением $\vec p (0)$.
Если для распределения вероятностей $\vec r (0) = (r_1(0),r_2(0),...)$ выполняется условие $\vec r (m)=\vec r(0)$ для всех $m \geq 1$, то $\vec r = (r_1,r_2,...)=\vec r(0)$ называется стационарным распределением вероятностей.

Если  предельное распределение вероятностей $\vec p (\infty)$ с начальным распределением $\vec p(0)$ существует, то оно будет стационарным, так как $\vec p(\infty)= \lim\limits_{m\to \infty } \vec p (m)= \lim\limits_{m \to \infty} \vec p (m+1) = [\lim\limits_{m \to \infty } \vec p (m)]P = \vec p (\infty ) P$.
Стационарное распределение вероятностей $\vec r = (r_1,r_2,...)$ удовлетворяет уравнениями $r_i=\sum_j r_j p_{ij}$, $i=1,2,...$ и $\sum_j r_j=1$ (уравнение нормировки).

Для конечной цепи Маркова с $n$ состояниями получается система
\[
	\begin{aligned}
		r_1 & = r_1 p_{11} + r_2 p_{21} + \dots + r_n p_{n1}, \\
		r_2 & = r_1 p_{12} + r_2 p_{22} + \dots + r_n p_{n2}, \\
		    & \ \ \vdots                                      \\
		r_n & = r_1 p_{1n} + r_2 p_{2n} + \dots + r_n p_{nn}, \\
		1   & = r_1 + r_2 + \dots + r_n.
	\end{aligned}
\]

Система из первых $n$ уравнений вырожденная, так как из $\vec{r} = \vec{r}P$
следует
$\vec{r}(P - E) = \vec{0}$, ($E$ - единичная матрица),
а матрица $(P - E)$ вырожденная:
\[
	\det(P - E) =
	\det \begin{pmatrix}
		p_{11} - 1 & \dots  & p_{1n}     \\
		\vdots     & \ddots & \vdots     \\
		p_{n1}     & \dots  & p_{nn} - 1
	\end{pmatrix}
	=
	\det \begin{pmatrix}
		p_{11} - 1 & \dots  & 0      \\
		\vdots     & \ddots & \vdots \\
		p_{n1}     & \dots  & 0
	\end{pmatrix}
	= 0.
\]

\subsubsection*{Эргодические цепи Маркова}

Цепь Маркова с переходной матрицей $P = (p_{ij})$ называется эргодической, если

1) существует предел
$\lim\limits_{k \to \infty} p_{ij}(k) = q_{ij};$

2) $q_{ij}$ не зависят от $i$:
$q_{ij} = q_j;$

3)
$q_j > 0 \quad \text{для всех } j.$

Теорема 1. Цепь Маркова эргодическая тогда и только тогда, когда

1) для любого начального распределения $\vec{p}(0)$ существует предел
$\lim\limits_{k \to \infty} p_{j}(k) = q_j;$

2) $q_j$ не зависят от начального распределения;

3) $q_j > 0$ для всех $j$.

Теорема 2. Если для конечной цепи Маркова с переходной матрицей $P=(p_{ij})$ среди корней характеристического уравнения $|P-\lambda E|=0$ условию $|\lambda|=1$ удовлетворяет только корень $\lambda=1$, то предельное распределение существует.

Теорема 3. Если условиях теоремы 2 корень $\lambda=1$ имеет кратность 1, то предельное распределение не зависит от начального распределения.

Теорема 4. (Теорема Маркова) Если для конечной цепи Маркова с переходной матрицей $P=(p_{ij})$ существует такое $S$, что $p_{ij}(s)>0 (P(s)=\{p_{ij}(s)\}=P^s)$ для всех $i$ и $j$, то цепь Маркова является эргодической.

Лемма. Пусть $Q=(q_{ij})$ - стохастическая матрица размерности $n \times n$,
$
	\vec{a} = \begin{pmatrix}
		a_1    \\
		a_2    \\
		\vdots \\
		a_n
	\end{pmatrix}
$ - произвольный вектор-столбец (размерности $n \times 1$), $\vec{b}=Q\vec{a}$; $m_{\vec{a}}=\min a_i$, $M_{\vec{a}}=\max a_i$ ($m_{\vec{b}}$ и $M_{\vec{b}}$ определяются для $\vec{b}$ аналогично).
Тогда:

1) $m\vec{a}\leq m\vec{b} \leq M\vec{b} \leq M\vec{a}$;

2) Если $q_{ij} \geq \varepsilon$ $\forall i,j$, то $M_{}\vec{b}-m_{\vec{b}} \leq  (1-2\varepsilon) (M_{}\vec{a}-m_{\vec{a})}$

\subsubsection*{Классификация состояний цепи Маркова}

Состояние $j$ достижимо из состояния $i$ [ обозначение: $i \to j$], если $\exists k: p_{ij}(k)>0$.
Очевидно, что из $i \to j$ и $j \to s$ следует $i \to s$.
Состояния $i$ и $j$ - сообщающиеся [обозначение $i \rightleftarrows j$] если $i \to j$ и $j \to i$.
Состояние $i$ - существенное, если из $i \to j$ следует $j \to i$.
Если $i$ - существенное состояние и $i \to j$, то состояние $j$ - существенное
Если для состояния $i$ существует такое состояние $j$, что $j$ достижимо из состояния $i$, но $i$ недостижимо из $j$, то состояние $i$ называется несущественным.

Пусть для существенного состояния $i$ $S(i)={j:i \rightleftarrows j}$. Все состояния $j\in S(i)$ являются существенными. Пространство $S$ всех состояний цепи Маркова можно представить в виде $S=S(i_1)\cup S(i_2)\cup ...\cup E$, где $E$ - множество всех несущественных состояний.

Цепь Маркова - неприводимая, если $S=S(i)$ для всех $i\in S$. Периодом состояния $i\in S$ называется $k_i=НОД(k: p_{ii}(k)>0)$.

Теорема. Если $i \rightleftarrows j$, то $k_i=k_j$.